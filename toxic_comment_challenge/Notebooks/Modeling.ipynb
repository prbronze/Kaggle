{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:17:54.318484Z",
     "start_time": "2020-10-20T20:17:54.225481Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.metrics import   roc_auc_score,multilabel_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif,f_classif\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "submission_file = pd.read_csv( '../.data/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now we want to have a glance at a baseline model, so we are not using nothing besides the comment_text with TF-IDF and a Logistic Regression with no tunning\n",
    "\n",
    "- Not using the features created in 'EDA.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:17:54.526941Z",
     "start_time": "2020-10-20T20:17:54.511037Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def import_train_data():\n",
    "    Xtrain = pd.read_csv('../.data/train_new_features.csv',index_col='id')\n",
    "    Xtr = Xtrain[['comment_text']]\n",
    "    ytr = Xtrain[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']]   \n",
    "    return Xtr,ytr\n",
    "\n",
    "def feature_extraction(Xtr,n_grams=(1,1),max_features=10000):\n",
    "    word_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        use_idf=True,\n",
    "        strip_accents='unicode',\n",
    "        stop_words='english',\n",
    "        min_df=20,\n",
    "        ngram_range=n_grams,\n",
    "        max_features=max_features)\n",
    "    \n",
    "    start = time.time()\n",
    "    print('Extracting fetures...')\n",
    "    train_features = word_vectorizer.fit_transform(Xtr['comment_text'])\n",
    "    print(f'Time elapsed: {time.time() - start} seconds. ')\n",
    "    param = word_vectorizer.get_params()\n",
    "    return train_features,param\n",
    "\n",
    "def train_model(Xtr,ytr,df_results,param_extractor,c_weight='balanced'):\n",
    "    \n",
    "    clf = LogisticRegression(class_weight=c_weight) #'balanced'\n",
    "    param_classifier = clf.get_params()\n",
    "    score_df = pd.DataFrame(columns=ytr.columns)\n",
    "    scores = []\n",
    "    \n",
    "    for col in ytr.columns:\n",
    "        cv_score = np.round(np.mean(cross_val_score(clf,\n",
    "                                           Xtr,\n",
    "                                           ytr[col],\n",
    "                                           cv=3,\n",
    "                                           scoring='roc_auc')),4)\n",
    "        scores.append(cv_score)\n",
    "        print(f'CV score for label {col} is {cv_score}.')\n",
    "        \n",
    "    scores.append(param_extractor)\n",
    "    scores.append(param_classifier)\n",
    "    df_results = df_results.append(dict(zip(df_results.columns,scores)), ignore_index = True)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:18:07.394815Z",
     "start_time": "2020-10-20T20:18:06.790427Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "x_train, y_train = import_train_data()\n",
    "list_cols = y_train.columns.to_list()\n",
    "list_cols.append('parameters_extraction')\n",
    "list_cols.append('parameters_classifier')\n",
    "score_df = pd.DataFrame(columns=list_cols)\n",
    "# x_train_transformed,parameters_feat_ext = feature_extraction(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T23:37:59.109193Z",
     "start_time": "2020-09-29T23:35:45.247269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for label toxic is 0.9675.\n",
      "CV score for label severe_toxic is 0.9851.\n",
      "CV score for label obscene is 0.9832.\n",
      "CV score for label threat is 0.9825.\n",
      "CV score for label insult is 0.9744.\n",
      "CV score for label identity_hate is 0.9732.\n",
      "CV score for label toxic is 0.9657.\n",
      "CV score for label severe_toxic is 0.9828.\n",
      "CV score for label obscene is 0.9813.\n",
      "CV score for label threat is 0.9819.\n",
      "CV score for label insult is 0.9729.\n",
      "CV score for label identity_hate is 0.9702.\n",
      "CV score for label toxic is 0.9624.\n",
      "CV score for label severe_toxic is 0.9806.\n",
      "CV score for label obscene is 0.9793.\n",
      "CV score for label threat is 0.9801.\n",
      "CV score for label insult is 0.9706.\n",
      "CV score for label identity_hate is 0.9674.\n"
     ]
    }
   ],
   "source": [
    "weights = [{0:1,1:1},{0:1,1:10},{0:1,1:100}]\n",
    "for w in weights:\n",
    "    score_df = train_model(x_train_transformed,y_train,\n",
    "                           score_df,parameters_feat_ext,c_weight=w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T01:04:12.509482Z",
     "start_time": "2020-09-30T01:04:12.486736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>parameters_extraction</th>\n",
       "      <th>parameters_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': {0: 1, 1: 1}, 'dual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': {0: 1, 1: 10}, 'dua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': {0: 1, 1: 100}, 'du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0  0.9675        0.9851   0.9832  0.9825  0.9744         0.9732   \n",
       "1  0.9675        0.9851   0.9832  0.9825  0.9744         0.9732   \n",
       "2  0.9657        0.9828   0.9813  0.9819  0.9729         0.9702   \n",
       "3  0.9624        0.9806   0.9793  0.9801  0.9706         0.9674   \n",
       "\n",
       "                               parameters_extraction  \\\n",
       "0  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "1  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "2  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "3  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "\n",
       "                               parameters_classifier  \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  \n",
       "1  {'C': 1.0, 'class_weight': {0: 1, 1: 1}, 'dual...  \n",
       "2  {'C': 1.0, 'class_weight': {0: 1, 1: 10}, 'dua...  \n",
       "3  {'C': 1.0, 'class_weight': {0: 1, 1: 100}, 'du...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not seem to be improving our scores so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:56:32.864569Z",
     "start_time": "2020-10-19T23:51:23.087259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fetures...\n",
      "Time elapsed: 18.977115392684937 seconds. \n",
      "CV score for label toxic is 0.9652.\n",
      "CV score for label severe_toxic is 0.9815.\n",
      "CV score for label obscene is 0.9807.\n",
      "CV score for label threat is 0.9808.\n",
      "CV score for label insult is 0.9726.\n",
      "CV score for label identity_hate is 0.9693.\n",
      "Extracting fetures...\n",
      "Time elapsed: 36.379775047302246 seconds. \n",
      "CV score for label toxic is 0.9645.\n",
      "CV score for label severe_toxic is 0.9813.\n",
      "CV score for label obscene is 0.9804.\n",
      "CV score for label threat is 0.9793.\n",
      "CV score for label insult is 0.9722.\n",
      "CV score for label identity_hate is 0.9679.\n",
      "Extracting fetures...\n",
      "Time elapsed: 54.11032557487488 seconds. \n",
      "CV score for label toxic is 0.964.\n",
      "CV score for label severe_toxic is 0.9813.\n",
      "CV score for label obscene is 0.9803.\n",
      "CV score for label threat is 0.9792.\n",
      "CV score for label insult is 0.972.\n",
      "CV score for label identity_hate is 0.9673.\n",
      "Extracting fetures...\n",
      "Time elapsed: 32.74915313720703 seconds. \n",
      "CV score for label toxic is 0.7668.\n",
      "CV score for label severe_toxic is 0.8384.\n",
      "CV score for label obscene is 0.777.\n",
      "CV score for label threat is 0.7882.\n",
      "CV score for label insult is 0.7822.\n",
      "CV score for label identity_hate is 0.7627.\n"
     ]
    }
   ],
   "source": [
    "list_cols = y_train.columns.to_list()\n",
    "list_cols.append('parameters_extraction')\n",
    "list_cols.append('parameters_classifier')\n",
    "score_df = pd.DataFrame(columns=list_cols)\n",
    "\n",
    "for n_gram_range in [(1,2),(1,3),(1,4),(2,3)]:\n",
    "    x_train_transformed,parameters_feat_ext = feature_extraction(x_train,n_gram_range)\n",
    "    score_df = train_model(x_train_transformed,y_train,\n",
    "                           score_df,parameters_feat_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T23:56:35.496739Z",
     "start_time": "2020-10-19T23:56:35.481427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>parameters_extraction</th>\n",
       "      <th>parameters_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.7627</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0  0.9652        0.9815   0.9807  0.9808  0.9726         0.9693   \n",
       "1  0.9645        0.9813   0.9804  0.9793  0.9722         0.9679   \n",
       "2  0.9640        0.9813   0.9803  0.9792  0.9720         0.9673   \n",
       "3  0.7668        0.8384   0.7770  0.7882  0.7822         0.7627   \n",
       "\n",
       "                               parameters_extraction  \\\n",
       "0  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "1  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "2  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "3  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "\n",
       "                               parameters_classifier  \n",
       "0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "1  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "2  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "3  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sucess.\n",
    "We could add more to max_features instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:22:12.938775Z",
     "start_time": "2020-10-20T20:18:30.213510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000.0\n",
      "Extracting fetures...\n",
      "Time elapsed: 6.39243483543396 seconds. \n",
      "CV score for label toxic is 0.9689.\n",
      "CV score for label severe_toxic is 0.9834.\n",
      "CV score for label obscene is 0.9833.\n",
      "CV score for label threat is 0.9814.\n",
      "CV score for label insult is 0.9755.\n",
      "CV score for label identity_hate is 0.9706.\n",
      "30000.0\n",
      "Extracting fetures...\n",
      "Time elapsed: 7.328493118286133 seconds. \n",
      "CV score for label toxic is 0.9689.\n",
      "CV score for label severe_toxic is 0.9834.\n",
      "CV score for label obscene is 0.9833.\n",
      "CV score for label threat is 0.9814.\n",
      "CV score for label insult is 0.9755.\n",
      "CV score for label identity_hate is 0.9706.\n",
      "50000.0\n",
      "Extracting fetures...\n",
      "Time elapsed: 7.240565061569214 seconds. \n",
      "CV score for label toxic is 0.9689.\n",
      "CV score for label severe_toxic is 0.9834.\n",
      "CV score for label obscene is 0.9833.\n",
      "CV score for label threat is 0.9814.\n",
      "CV score for label insult is 0.9755.\n",
      "CV score for label identity_hate is 0.9706.\n"
     ]
    }
   ],
   "source": [
    "list_cols = y_train.columns.to_list()\n",
    "list_cols.append('parameters_extraction')\n",
    "list_cols.append('parameters_classifier')\n",
    "score_df = pd.DataFrame(columns=list_cols)\n",
    "\n",
    "for max_feats in [1.5e4,3e4,5e4]:\n",
    "    print(max_feats)\n",
    "    x_train_transformed,parameters_feat_ext = feature_extraction(x_train,\n",
    "                                                                 max_features=int(max_feats))\n",
    "    score_df = train_model(x_train_transformed,y_train,\n",
    "                           score_df,parameters_feat_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T00:33:27.564371Z",
     "start_time": "2020-10-20T00:33:27.554623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>parameters_extraction</th>\n",
       "      <th>parameters_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>{'analyzer': 'word', 'binary': False, 'decode_...</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0  0.9689        0.9834   0.9833  0.9814  0.9755         0.9706   \n",
       "1  0.9689        0.9834   0.9833  0.9814  0.9755         0.9706   \n",
       "2  0.9689        0.9834   0.9833  0.9814  0.9755         0.9706   \n",
       "\n",
       "                               parameters_extraction  \\\n",
       "0  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "1  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "2  {'analyzer': 'word', 'binary': False, 'decode_...   \n",
       "\n",
       "                               parameters_classifier  \n",
       "0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "1  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "2  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we seem to reach something, but the model does not seem to show any improvement with more than 15k terms.\n",
    "We could try now work with both max_features and n_gram_range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:34:35.637866Z",
     "start_time": "2020-10-20T20:27:46.617611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fetures...\n",
      "Time elapsed: 18.222862005233765 seconds. \n",
      "CV score for label toxic is 0.9669.\n",
      "CV score for label severe_toxic is 0.9828.\n",
      "CV score for label obscene is 0.9818.\n",
      "CV score for label threat is 0.9807.\n",
      "CV score for label insult is 0.9738.\n",
      "CV score for label identity_hate is 0.9707.\n",
      "Extracting fetures...\n",
      "Time elapsed: 35.48916292190552 seconds. \n",
      "CV score for label toxic is 0.9664.\n",
      "CV score for label severe_toxic is 0.9823.\n",
      "CV score for label obscene is 0.9813.\n",
      "CV score for label threat is 0.9808.\n",
      "CV score for label insult is 0.9732.\n",
      "CV score for label identity_hate is 0.9707.\n",
      "Extracting fetures...\n",
      "Time elapsed: 19.025423765182495 seconds. \n",
      "CV score for label toxic is 0.9691.\n",
      "CV score for label severe_toxic is 0.9839.\n",
      "CV score for label obscene is 0.9835.\n",
      "CV score for label threat is 0.9822.\n",
      "CV score for label insult is 0.9757.\n",
      "CV score for label identity_hate is 0.9713.\n",
      "Extracting fetures...\n",
      "Time elapsed: 36.50981831550598 seconds. \n",
      "CV score for label toxic is 0.9688.\n",
      "CV score for label severe_toxic is 0.9838.\n",
      "CV score for label obscene is 0.9833.\n",
      "CV score for label threat is 0.9818.\n",
      "CV score for label insult is 0.9755.\n",
      "CV score for label identity_hate is 0.971.\n"
     ]
    }
   ],
   "source": [
    "list_cols = y_train.columns.to_list()\n",
    "list_cols.append('parameters_extraction')\n",
    "list_cols.append('parameters_classifier')\n",
    "score_df = pd.DataFrame(columns=list_cols)\n",
    "# 3e4 and (1,2)\n",
    "for max_feats in [1.5e4,3e4]:\n",
    "    for n_gram_range in [(1,2),(1,3)]:\n",
    "    \n",
    "        x_train_transformed,parameters_feat_ext = feature_extraction(x_train,\n",
    "                                                                     n_gram_range,\n",
    "                                                                     int(max_feats))\n",
    "        score_df = train_model(x_train_transformed,y_train,\n",
    "                               score_df,parameters_feat_ext)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once best hyperparameter for feature extraction:\n",
    "\n",
    "Model Diagnosing:\n",
    "    - from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_l_curve(estimator, X, y, cv=5, n_jobs=4):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(model,\n",
    "                                                             X,\n",
    "                                                             y,\n",
    "                                                             train_sizes=[0.05,0.1,0.2,0.50.75],\n",
    "                                                             cv=cv)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_l_curve(estimator, X, y, cv=cv, n_jobs=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
